{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.layout import LAParams, LTLine, LTRect, LTTextBoxHorizontal\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from difflib import get_close_matches, SequenceMatcher\n",
    "from validate_docbr import CPF\n",
    "from os import path, listdir\n",
    "from pandas import read_csv\n",
    "# from xlwings import Book\n",
    "import requests\n",
    "import nltk\n",
    "\n",
    "from ast import literal_eval\n",
    "import json\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "import zipfile\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "\n",
    "# dateUrl = datetime.now()\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         fileHandle, _ = urlretrieve('http://www.portaltransparencia.gov.br/download-de-dados/servidores/' + dateUrl.strftime('%Y%m') + '_Servidores.zip')\n",
    "#         break\n",
    "#     except:\n",
    "#         dateUrl -= relativedelta(months=1)\n",
    "#         print('http://www.portaltransparencia.gov.br/download-de-dados/servidores/' + dateUrl.strftime('%Y%m') + '_Servidores.zip')\n",
    "\n",
    "# zipFile = zipfile.ZipFile(fileHandle, 'r')\n",
    "\n",
    "# dfsTransparencia = {}\n",
    "# for fileName in zipFile.namelist():\n",
    "#     if fileName.split('_')[1] in ['Remuneracao.csv', 'Cadastros.csv']:\n",
    "#         csvData = zipFile.open(fileName)\n",
    "\n",
    "#         dfsTransparencia[fileName.split('_')[1]] = read_csv(csvData, sep=';', engine='c', low_memory=False, encoding='latin-1')\n",
    "\n",
    "# del zipFile, fileHandle, dateUrl, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def check_portal_transparencia(self):\n",
    "#         cpfPiecesList = re.findall('\\d\\d\\d?', self.cpf)\n",
    "#         cpfToFind = f'***.{cpfPiecesList[1]}.{cpfPiecesList[2]}-**'\n",
    "        \n",
    "#         remuneracao = dfsTransparencia['Remuneracao.csv'][(dfsTransparencia['Remuneracao.csv']['CPF'] == cpfToFind) & (dfsTransparencia['Remuneracao.csv']['NOME'] == self.name)]\n",
    "#         cadastro = dfsTransparencia['Cadastros.csv'][(dfsTransparencia['Remuneracao.csv']['CPF'] == cpfToFind) & (dfsTransparencia['Remuneracao.csv']['NOME'] == self.name)]\n",
    "        \n",
    "#         assert remuneracao.shape[0] or cadastro.shape[0], f'SERVIDOR NOT FOUND IN \"Portal Transparencia\" ' + today.strftime('%d/%m/%Y, %H:%M') + f'\\nCPF: {self.cpf} and Name: {self.name}\\n\\n'\n",
    "        \n",
    "#         idServidor, remuneracaoBasicaBruta = remuneracao[['Id_SERVIDOR_PORTAL', 'REMUNERAÇÃO BÁSICA BRUTA (R$)']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract_Image_Text:\n",
    "    def __init__(self, path, credentials):\n",
    "        self.clientVision = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "        self.content = io.open(path, 'rb').read()\n",
    "\n",
    "        self.image = vision.Image(content=self.content)\n",
    "        self.cv2image = cv2.imread(path)\n",
    "    \n",
    "    def text_detection(self):\n",
    "        return self.clientVision.text_detection(image=self.image)\n",
    "\n",
    "    def document_text_detection(self):\n",
    "        return self.clientVision.document_text_detection(image=self.image)\n",
    "    \n",
    "\n",
    "def get_text_annotations(visionObj):\n",
    "    objDescription = visionObj.text_annotations[0].description\n",
    "    return {'splited':objDescription.split('\\n'), 'concatenated':objDescription.replace('\\n', '')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = r'/mnt/e/Aram/Projeto_KGB/Documentos/015.639.431-66/015.639.431-66_CPF_345230_19042021144053048.JPG'\n",
    "b = r'/mnt/e/Aram/Projeto_KGB/Documentos/015.639.431-66/015.639.431-66_DOC IDENT V_345230_19042021144053045.JPG'\n",
    "\n",
    "im1 = cv2.imread(a)\n",
    "im2 = cv2.imread(b)\n",
    "\n",
    "\n",
    "def MSE(imageA, imageB):\n",
    "\terr = np.sum(np.square(imageA.astype(\"float\") - imageB.astype(\"float\")))\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\treturn err\n",
    "\n",
    "\n",
    "assert im1.shape == im2.shape and MSE(im1, im2) <= 200, f'SAME TYPE OF DOCUMENT (IMAGE) DIFERENT CONTENT, MSE: {im1} <> {im2}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Checker at 0x219a1d48b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como verificar holerite\n",
    "# O que eu ja fiz\n",
    "# verificar assinatura Sim\n",
    "\n",
    "pathKGB = path.normpath(r'/mnt/e/Aram/Projeto_KGB')\n",
    "pathDir = path.join(pathKGB, 'Documentos')\n",
    "foldersCPFsNames = listdir(pathDir)\n",
    "\n",
    "\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, cpf, pathFichaCadastral):\n",
    "        self.cpf = cpf\n",
    "        self.pathFichaCadastral = pathFichaCadastral\n",
    "        \n",
    "        dictObjsDataFichaCadastral = self.process_ficha_cadastral()\n",
    "        \n",
    "        self.name = dictObjsDataFichaCadastral['nome completo:'].get_text().replace('\\n', '').lower()\n",
    "        self.dataNascimento = datetime.strptime(dictObjsDataFichaCadastral['data nascimento:'].get_text().replace('\\n', ''), \"%d/%m/%Y\")\n",
    "        self.idade = round((today - self.dataNascimento).days/365.25, 3)\n",
    "        \n",
    "        # Check CPF\n",
    "        assert self.cpf == dictObjsDataFichaCadastral['cpf:'].get_text().replace('\\n', ''), today.strftime('%d/%m/%Y, %H:%M') + f' <Client>\\n{self.cnpj} NOT FOUND IN \"FICHA CADASTRAL\"'\n",
    "        \n",
    "        self.nDocIdentidade = dictObjsDataFichaCadastral['nº documento de identidade:'].get_text().replace('\\n', '').lower()\n",
    "        self.uf = dictObjsDataFichaCadastral['uf:'].get_text().replace('\\n', '').lower()\n",
    "        self.cep = dictObjsDataFichaCadastral['cep:'].get_text().replace('\\n', '')\n",
    "        \n",
    "        self.dataContratacao = datetime.strptime(dictObjsDataFichaCadastral['tempo de serviço:'].get_text().replace('\\n', ''), \"%d/%m/%Y\")\n",
    "        self.ondeTrabalha = dictObjsDataFichaCadastral['empresa/orgão:'].get_text().replace('\\n', '').lower()\n",
    "        self.salario = float(dictObjsDataFichaCadastral['salário:'].get_text().replace('\\n', '').replace('R$', '').replace(',', '-').replace('.', '').replace('-', '.'))\n",
    "\n",
    "\n",
    "    def parse_obj(self, lt_objs):\n",
    "        # Processa os objetos do pdf\n",
    "        def distance_boxes_RL_DT(box1, box2):\n",
    "            #  _____\n",
    "            # |____|\n",
    "            #      \\_____\n",
    "            #      |____|\n",
    "            return (box1[2] - box2[0])**2 + (box1[1] - box2[1])**2\n",
    "        \n",
    "        listCampos = ['nome completo:', 'cpf:', 'data nascimento:', 'cep:', 'empresa/orgão:',\n",
    "                      'uf:', 'nº documento de identidade:', 'tempo de serviço:', 'salário:']\n",
    "        dictCampos = {}\n",
    "        state = True\n",
    "        \n",
    "        for obj in lt_objs:\n",
    "            if isinstance(obj, LTTextBoxHorizontal):\n",
    "                if state:\n",
    "                    valToEverybody = obj\n",
    "                    state = False\n",
    "                \n",
    "                for campo in listCampos:\n",
    "                    if obj.get_text().replace('\\n', '').lower() == campo:\n",
    "                        try:\n",
    "                            if obj.bbox[1] > dictCampos[campo].bbox[1]:\n",
    "                                dictCampos[campo] = obj\n",
    "                        except:\n",
    "                            dictCampos[campo] = obj\n",
    "                        break\n",
    "\n",
    "        dictCamposVals = {_:valToEverybody for _ in listCampos}\n",
    "\n",
    "        for obj in lt_objs:\n",
    "            if isinstance(obj, LTTextBoxHorizontal):\n",
    "                \n",
    "                for campo in listCampos:\n",
    "                    if (\n",
    "                        dictCampos[campo].bbox[0] < obj.bbox[0] and obj.bbox[1] <= dictCampos[campo].bbox[3] and\n",
    "                        distance_boxes_RL_DT(dictCampos[campo].bbox, obj.bbox) < distance_boxes_RL_DT(dictCampos[campo].bbox, dictCamposVals[campo].bbox)\n",
    "                    ): dictCamposVals[campo] = obj\n",
    "        \n",
    "        return dictCamposVals\n",
    "\n",
    "\n",
    "    def process_ficha_cadastral(self):\n",
    "        # Lê o pdf \"FICHA CADASTRAL\"\n",
    "        with open(self.pathFichaCadastral, 'rb') as fichaCadastral:\n",
    "            parser = PDFParser(fichaCadastral)\n",
    "            doc = PDFDocument(parser)\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            device = PDFDevice(rsrcmgr)\n",
    "            device = PDFPageAggregator(rsrcmgr, laparams=LAParams())\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            \n",
    "            for page in PDFPage.create_pages(doc):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "\n",
    "                dictCamposVals = self.parse_obj(layout._objs)\n",
    "            fichaCadastral.close()\n",
    "\n",
    "        return dictCamposVals\n",
    "\n",
    "\n",
    "class CCB:\n",
    "    def __init__(self, client, pathCCB):\n",
    "        self.client = client\n",
    "        self.pathCCB = pathCCB\n",
    "        \n",
    "        self.clienteCCB, self.CCB = self.process_CCB()\n",
    "    \n",
    "\n",
    "    def parse_obj(self, lt_objs):\n",
    "        # Processa os objetos do pdf\n",
    "        def distance_boxes_RL_TT(box1, box2):\n",
    "            #  ______________\n",
    "            # |____|   |____|\n",
    "            return (box1[2] - box2[0])**2 + (box1[3] - box2[3])**2\n",
    "        \n",
    "        \n",
    "        def distance_boxes_centerL_LR(box1, box2):\n",
    "            #   _____\n",
    "            #  |____|\n",
    "            #  ___|_\n",
    "            # |____|\n",
    "            return ((box1[0] + box1[2]*2)/3 - (box2[0] + box2[2])/2)**2 + (box1[1] - box2[3])**2\n",
    "            \n",
    "        listCamposInfosCliente = ['nome/razão social:', 'cpf/cnpj:', 'cep:', 'estado:', 'rg:',\n",
    "                                  '5.1. valor total da dívida:']# TODO: 'assinatura emitente:'\n",
    "        listCamposInfosCCB = ['céduladecréditobancário', '5.vencimento-tododia', 'quantidadedeparcelas',\n",
    "                              'últimovencimento', 'primeirovencimento', 'totaldaparcela', 'principal', 'juros']\n",
    "        \n",
    "        dictCamposInfosCliente = {}\n",
    "        dictCamposInfosCCB = {}\n",
    "                \n",
    "        for obj in lt_objs:\n",
    "            if isinstance(obj, LTTextBoxHorizontal):\n",
    "                if len(dictCamposInfosCliente) == 2:\n",
    "                    valToEverybody = obj\n",
    "                \n",
    "                for campo in listCamposInfosCliente + listCamposInfosCCB:\n",
    "                    objTxtReplacedLower = obj.get_text().replace('\\n', '').replace(' ', '').lower()\n",
    "                    \n",
    "                    if re.search('^' + campo, objTxtReplacedLower) != None and campo in listCamposInfosCCB:\n",
    "                        try:\n",
    "                            if obj.bbox[1] > dictCamposInfosCCB[campo].bbox[1]:\n",
    "                                dictCamposInfosCCB[campo] = obj\n",
    "                        except:\n",
    "                            dictCamposInfosCCB[campo] = obj\n",
    "                        break\n",
    "                    \n",
    "                    elif obj.get_text().replace('\\n', '').lower() == campo:\n",
    "                        try:\n",
    "                            if obj.bbox[1] > dictCampos[campo].bbox[1]:\n",
    "                                dictCamposInfosCliente[campo] = obj\n",
    "                        except:\n",
    "                            dictCamposInfosCliente[campo] = obj\n",
    "\n",
    "            # Pegas as linhas (que formam tabelas) da pagina\n",
    "#             elif isinstance(obj, LTLine):\n",
    "#                 pass\n",
    "        \n",
    "        dictCamposInfosClienteVals = {_:valToEverybody for _ in listCamposInfosCliente}\n",
    "        dictCamposInfosCCBVals = {_:valToEverybody for _ in listCamposInfosCCB}\n",
    "\n",
    "        for obj in lt_objs:            \n",
    "            if isinstance(obj, LTTextBoxHorizontal):\n",
    "                for campo in listCamposInfosCliente:\n",
    "                    if (\n",
    "                        dictCamposInfosCliente[campo].bbox[2] < obj.bbox[0] and\n",
    "                        distance_boxes_RL_TT(dictCamposInfosCliente[campo].bbox, obj.bbox) < distance_boxes_RL_TT(dictCamposInfosCliente[campo].bbox, dictCamposInfosClienteVals[campo].bbox)\n",
    "                    ): dictCamposInfosClienteVals[campo] = obj\n",
    "                \n",
    "                for campo in listCamposInfosCCB:\n",
    "                    if (\n",
    "                        obj != dictCamposInfosCCB[campo] and obj.bbox[1] < dictCamposInfosCCB[campo].bbox[1] and # obj.bbox[3] < dictCamposInfosCCB[campo].bbox[3] and\n",
    "                        distance_boxes_centerL_LR(dictCamposInfosCCB[campo].bbox, obj.bbox) < distance_boxes_centerL_LR(dictCamposInfosCCB[campo].bbox, dictCamposInfosCCBVals[campo].bbox)\n",
    "                    ): dictCamposInfosCCBVals[campo] = obj\n",
    "        \n",
    "        return dictCamposInfosClienteVals, dictCamposInfosCCBVals\n",
    "            \n",
    "    def process_CCB(self):\n",
    "        # Lê o pdf \"CCB\"\n",
    "        with open(self.pathCCB, 'rb') as ccb:\n",
    "            parser = PDFParser(ccb)\n",
    "            doc = PDFDocument(parser)\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            device = PDFPageAggregator(rsrcmgr, laparams=LAParams(line_margin=0.35))\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "            \n",
    "            for page in PDFPage.create_pages(doc):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "\n",
    "                dictCliente, dictCCB = self.parse_obj(layout._objs)\n",
    "                break\n",
    "            ccb.close()\n",
    "        \n",
    "        return dictCliente, dictCCB\n",
    "\n",
    "\n",
    "class Checker:\n",
    "    def __init__(self, cpf, pathDocuments):\n",
    "        self.cpf = cpf\n",
    "        self.pathDocuments = pathDocuments\n",
    "        \n",
    "        filesNames = listdir(self.pathDocuments)\n",
    "\n",
    "        self.paths = {_: list() for _ in ['fichaCadastral', 'gravacao', 'ccb', 'holerite', 'comp', 'averbacao']}\n",
    "        self.paths.update({'docs':{}, 'others':{}})\n",
    "        \n",
    "        fileNotCoresponded = []\n",
    "        \n",
    "        # Validar CPF\n",
    "        CPFValidator = CPF()\n",
    "        assert CPFValidator.validate(self.cpf), 'NOT VALID CPF ' + today.strftime('%d/%m/%Y, %H:%M') + f' - cpf: {self.cpf}\\n\\n'\n",
    "\n",
    "        for cont, fileName in enumerate(filesNames):\n",
    "            listNameParts = fileName.split('_')\n",
    "            pathFile = path.join(self.pathDocuments, fileName)\n",
    "            \n",
    "            if listNameParts[0] == folderDocumentsName:\n",
    "                if listNameParts[1].lower().replace(' ', '')[:14] == 'fichacadastral':\n",
    "                    self.paths['fichaCadastral'].append(pathFile)\n",
    "                elif listNameParts[1].lower() == 'gravacao':\n",
    "                    self.paths['gravacao'].append(pathFile)\n",
    "                elif listNameParts[1].lower() == 'holerite':\n",
    "                    self.paths['holerite'].append(pathFile)\n",
    "                elif listNameParts[1].lower()[:3] == 'ccb':\n",
    "                    self.paths['ccb'].append(pathFile)\n",
    "                elif listNameParts[1].lower() == 'cpf':\n",
    "                    try:\n",
    "                        self.paths['docs']['cpf'].append(pathFile)\n",
    "                    except:\n",
    "                        self.paths['docs']['cpf'] = []\n",
    "                        self.paths['docs']['cpf'].append(pathFile)\n",
    "                elif listNameParts[1].lower().replace(' ', '')[:8] == 'docident':\n",
    "                    try:\n",
    "                        self.paths['docs']['docs'].append(pathFile)\n",
    "                    except:\n",
    "                        self.paths['docs']['docs'] = []\n",
    "                        self.paths['docs']['docs'].append(pathFile)\n",
    "                elif listNameParts[1].lower() == 'comp':\n",
    "                    self.paths['comp'].append(pathFile)\n",
    "                elif listNameParts[1].lower() == 'averbacao':\n",
    "                    self.paths['averbacao'].append(pathFile)\n",
    "                else:\n",
    "                    self.paths['others'][listNameParts[1].lower()] = pathFile\n",
    "            else:\n",
    "                # Colocar no arquivo de erros que foi encontrado um arquivo sem\n",
    "                # o cpf no começo levanta um erro que não comprometa o codigo\n",
    "                fileNotCoresponded.append(pathFile)\n",
    "        \n",
    "        # TODO: Verificar Duplicatas\n",
    "        \n",
    "        # Passa os outros para um aruivo, para fins de controle\n",
    "        if self.paths['others'] or fileNotCoresponded:\n",
    "            pathOthersFile = path.join(pathKGB, 'Others.txt')\n",
    "            with open(pathOthersFile, 'a') as othersFile:\n",
    "                othersFile.write(today.strftime('%d/%m/%Y, %H:%M') + '\\n' + dumps({self.cpf:{'Others':list(self.paths['others'].items()), 'Not coresponded':fileNotCoresponded}}, indent=4) + '\\n\\n\\n')\n",
    "                othersFile.close()\n",
    "        del fileNotCoresponded\n",
    "        \n",
    "        # Da um AssertionError caso algum dos tipos de documento obrigatorio\n",
    "        # não tiver nenhum arquivo relacionado\n",
    "        errores = []\n",
    "        for fileType in self.paths.keys():\n",
    "            if fileType == 'docs' and not self.paths[fileType]['cpf']: # Checa se não existe um documento CPF\n",
    "                errores.append('cpf')\n",
    "            elif not self.paths[fileType] and fileType != 'others': # Checa se não algum dos outros não existe menos 'others'\n",
    "                errores.append(fileType)\n",
    "        assert not errores, 'FILE NOT FOUND ' + today.strftime('%d/%m/%Y, %H:%M') + '\\n' + dumps({'cpf':self.cpf, 'Files Types':[_ for _ in errores]}, indent=4) + '\\n\\n\\n'\n",
    "        del errores\n",
    "\n",
    "        self.cliente = Client(self.cpf, self.paths['fichaCadastral'][0])\n",
    "        \n",
    "        self.CCB = CCB(self.cliente, self.paths['ccb'][0])\n",
    "        \n",
    "        objReceitaHolerite, *_ = self.validate_holerite()\n",
    "        receitaHolerite = float(objReceitaHolerite.get_text().replace('\\n', '').replace('R$', '').replace(',', ' ').replace('.', '').replace(' ', '.'))\n",
    "        assert self.cliente.salario == receitaHolerite, '\"Receita/Salário\" NOT CORRESPONDENT ' + today.strftime('%d/%m/%Y, %H:%M') + f'\\ncpf: {self.cpf}, name: {self.cliente.name},' +\\\n",
    "                                                        f'\\nReseita holerite: {str(receitaHolerite)}, salario ficha: {str(self.cliente.salario)}'\n",
    "#         self.validate_antifraude()\n",
    "        \n",
    "        self.validate_transparencia()\n",
    "        \n",
    "        # TODO: holerite bater com portal maximo 10% de diferença para menos\n",
    "    \n",
    "    def validate_holerite(self):\n",
    "        def parse_obj(lt_objs):\n",
    "            def distance_boxes_centerL_LR(box1, box2):\n",
    "                #   _____\n",
    "                #  |____|\n",
    "                #  __|__\n",
    "                # |____|\n",
    "                return ((box1[0] + box1[2])/2 - (box2[0] + box2[2])/2)**2 + (box1[1] - box2[3])**2\n",
    "            \n",
    "            listVariaveisCampoReceita = ['bruto', 'receita']\n",
    "            listDadosCliente = [self.cpf, self.cliente.name]\n",
    "            \n",
    "            cpfAsNumber = self.cpf.replace('.', '').replace('-', '')\n",
    "            names = self.cliente.name.split(' ')\n",
    "            names = [names[0], names[-1]]\n",
    "            \n",
    "            for obj in lt_objs:\n",
    "                if isinstance(obj, LTTextBoxHorizontal):\n",
    "                    objTextLower = obj.get_text().replace('\\n', '').lower()\n",
    "\n",
    "                    if objTextLower.find(listVariaveisCampoReceita[0]) != -1 or objTextLower.find(listVariaveisCampoReceita[1]) != -1:\n",
    "                        try:\n",
    "                            if obj.bbox[1] < objReceita.bbox[1]:\n",
    "                                objReceita = obj\n",
    "                        except:\n",
    "                            objReceita = obj\n",
    "                                \n",
    "                    if objTextLower.replace('.', '').replace('-', '').find(cpfAsNumber) != -1:\n",
    "                        objCpf = obj\n",
    "                    else:\n",
    "                        if objTextLower.find(names[0]) != -1 and objTextLower.find(names[1]) != -1:\n",
    "                            objName = obj\n",
    "            \n",
    "            objReceitaValor = objReceita\n",
    "            \n",
    "            for obj in lt_objs:\n",
    "                if isinstance(obj, LTTextBoxHorizontal):\n",
    "                    if (\n",
    "                        obj.bbox != objReceita.bbox and\n",
    "                        distance_boxes_centerL_LR(objReceita.bbox, obj.bbox) < distance_boxes_centerL_LR(objReceita.bbox, objReceitaValor.bbox)\n",
    "                    ): objReceitaValor = obj\n",
    "            \n",
    "            assert 'objName' in locals() and 'objCpf' in locals(), 'CPF OR NAME NOT FOUND IN HOLERITE ' + today.strftime('%d/%m/%Y, %H:%M') + f'\\ncpf: {self.cpf}, name: {self.cliente.name}'\n",
    "            \n",
    "            return (objReceitaValor, objName, objCpf)\n",
    "                    \n",
    "        \n",
    "        with open(self.paths['holerite'][0], 'rb') as holerite:\n",
    "            parser = PDFParser(holerite)\n",
    "            doc = PDFDocument(parser)\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            device = PDFPageAggregator(rsrcmgr, laparams=LAParams(line_margin=0.2))\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "            for page in PDFPage.create_pages(doc):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "\n",
    "                tupObjs = parse_obj(layout._objs)\n",
    "                break\n",
    "                \n",
    "            holerite.close()\n",
    "        \n",
    "        return tupObjs\n",
    "            \n",
    "    \n",
    "    def validate_antifraude(self):\n",
    "        def parse_obj(lt_objs):\n",
    "            def distance_boxes_center_LR(box1, box2):\n",
    "                #  _____     _____\n",
    "                # |____|----|____|\n",
    "                return (box1[2] - box2[0])**2 + ((box1[1] + box1[3])/2 - (box2[1] + box2[3])/2)**2\n",
    "\n",
    "            \n",
    "            def distance_boxes_left_TD(box1, box2):\n",
    "                #  _____\n",
    "                # |____|\n",
    "                # \\_____\n",
    "                # |____|\n",
    "                return (box1[0] - box2[0])**2 + (box1[1] - box2[3])**2\n",
    "            \n",
    "            \n",
    "            listCamposCliente, listCamposStatus = ['nome', 'cpf'], ['status:', 'motivo:', 'observação:']\n",
    "\n",
    "            dictCampos = {}\n",
    "\n",
    "            for obj in lt_objs:\n",
    "                if isinstance(obj, LTTextBoxHorizontal):\n",
    "                    if len(dictCampos) == 2 and not obj.get_text().replace('\\n', '').lower() in listCamposCliente + listCamposStatus:\n",
    "                        valToEverybody = obj\n",
    "\n",
    "                    for campo in listCamposCliente + listCamposStatus:\n",
    "\n",
    "                        if obj.get_text().replace('\\n', '').lower() == campo or obj.get_text().replace('\\n', '').lower().split(' ')[0] == campo:\n",
    "                            try:\n",
    "                                if obj.bbox[1] > dictCampos[campo].bbox[1]:\n",
    "                                    dictCampos[campo] = obj\n",
    "                            except:\n",
    "                                dictCampos[campo] = obj\n",
    "            \n",
    "            dictCamposVals = {_:valToEverybody for _ in listCamposCliente + listCamposStatus}            \n",
    "\n",
    "            for obj in lt_objs:\n",
    "                if isinstance(obj, LTTextBoxHorizontal):\n",
    "                    for campo in listCamposCliente:\n",
    "                        if (\n",
    "                            obj.bbox[3] < dictCampos[campo].bbox[1] and\n",
    "                            distance_boxes_left_TD(dictCampos[campo].bbox, obj.bbox) < distance_boxes_left_TD(dictCampos[campo].bbox, dictCamposVals[campo].bbox)\n",
    "                        ): dictCamposVals[campo] = obj\n",
    "\n",
    "                    for campo in listCamposStatus:\n",
    "                        if (\n",
    "                            dictCampos[campo].bbox[2] < obj.bbox[0] and\n",
    "                            distance_boxes_center_LR(dictCampos[campo].bbox, obj.bbox) < distance_boxes_center_LR(dictCampos[campo].bbox, dictCamposVals[campo].bbox)\n",
    "                        ): dictCamposVals[campo] = obj\n",
    "            \n",
    "            \n",
    "        with open(self.paths['others']['antifraude'], 'rb') as antifraude:\n",
    "            parser = PDFParser(antifraude)\n",
    "            doc = PDFDocument(parser)\n",
    "            rsrcmgr = PDFResourceManager()\n",
    "            device = PDFPageAggregator(rsrcmgr, laparams=LAParams())\n",
    "            interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "            for page in PDFPage.create_pages(doc):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "\n",
    "                dictAntifraude = parse_obj(layout._objs)\n",
    "                break\n",
    "\n",
    "            antifraude.close()\n",
    "    \n",
    "    \n",
    "    def validate_transparencia(self):\n",
    "        head = {'accept': '*/*', 'chave-api-dados': 'cb76e5b1a35c4a24e84b7fde2d1a0244'}\n",
    "\n",
    "        cpf = self.cpf.replace('.', '').replace('-', '')\n",
    "        requestTransparencia = requests.get(f'http://api.portaldatransparencia.gov.br/api-de-dados/servidores/remuneracao?cpf={cpf}&mesAno={str(202009)}&pagina=1', headers=head)\n",
    "\n",
    "        assert requestTransparencia.status_code != 404, '<404> NOT FOUND IN \"portaldatransparencia.gov.br\"' + today.strftime('%d/%m/%Y, %H:%M') + f'\\ncpf: {self.cpf}, name: {self.cliente.name}'\n",
    "        assert requestTransparencia.status_code != 403, '<403> FORBIDDEN \"portaldatransparencia.gov.br\"' + today.strftime('%d/%m/%Y, %H:%M') + f'\\ncpf: {self.cpf}, name: {self.cliente.name}'\n",
    "        assert requestTransparencia.status_code != 401, '<401> UNAUTHORIZED \"portaldatransparencia.gov.br\"' + today.strftime('%d/%m/%Y, %H:%M') + f'\\ncpf: {self.cpf}, name: {self.cliente.name}'\n",
    "        \n",
    "#         print(json.loads(requestTransparencia.text)[0]['remuneracoesDTO'])#['remuneracoesDTO'])\n",
    "        pessoa = json.loads(requestTransparencia.text)[0]['servidor']['pessoa']\n",
    "        name = pessoa['nome'].strip().lower()\n",
    "\n",
    "        assert self.cliente.name == name, 'NAME NOT CORRESPONDENT IN \"portaldatransparencia.gov.br\"' + today.strftime('%d/%m/%Y, %H:%M') + f'\\ncpf: {self.cpf}, name: {self.cliente.name}'\n",
    "\n",
    "\n",
    "    def check_duplicates_PDFs(self):\n",
    "        c = r'/mnt/e/Aram/Projeto_KGB/Documentos/929.644.434-91/929.644.434-91_HOLERITE_344856_19042021144052230.PDF'\n",
    "        d = r'/mnt/e/Aram/Projeto_KGB/Documentos/929.644.434-91/929.644.434-91_HOLERITE_344856_19042021144052284.PDF'\n",
    "\n",
    "        paths = [c, d]\n",
    "\n",
    "        for cont, pathPDF in enumerate(paths):\n",
    "            with open(pathPDF, 'rb') as in_file:\n",
    "                parser = PDFParser(in_file)\n",
    "                doc = PDFDocument(parser)\n",
    "                rsrcmgr = PDFResourceManager()\n",
    "                device = TextConverter(rsrcmgr, output_strings[cont], laparams=LAParams())\n",
    "                interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "                for page in PDFPage.create_pages(doc):\n",
    "                    interpreter.process_page(page)\n",
    "\n",
    "\n",
    "        assert output_strings[0].getvalue() == output_strings[1].getvalue(), 'SAME TYPE OF DOCUMENT (PDF) DIFERENT CONTENT ' + today.strftime('%d/%m/%Y, %H:%M') + f'\\n{self.cpf}; Doc Type: {key}'\n",
    "\n",
    "    def check_duplicates_images(self):\n",
    "        im1 = cv2.imread(a)\n",
    "        im2 = cv2.imread(b)\n",
    "\n",
    "\n",
    "        def MSE(imageA, imageB):\n",
    "            err = np.sum(np.square(imageA.astype(\"float\") - imageB.astype(\"float\")))\n",
    "            err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "            return err\n",
    "\n",
    "\n",
    "        assert im1.shape == im2.shape and MSE(im1, im2) <= 200, f'SAME TYPE OF DOCUMENT (IMAGE) DIFERENT CONTENT, MSE: {im1} <> {im2}\\n'\n",
    "\n",
    "\n",
    "today = datetime.now()\n",
    "\n",
    "folderDocumentsName = foldersCPFsNames[1]\n",
    "pathDocuments = path.join(pathDir, folderDocumentsName)\n",
    "\n",
    "Checker(folderDocumentsName, pathDocuments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathPDF = r'/mnt/e/Aram/Projeto_KGB/Documentos/015.639.431-66/015.639.431-66_HOLERITE_345230_19042021144052970.PDF'\n",
    "\n",
    "output_string = StringIO()\n",
    "with open(pathPDF, 'rb') as in_file:\n",
    "    parser = PDFParser(in_file)\n",
    "    doc = PDFDocument(parser)\n",
    "    print(doc.info)\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    for page in PDFPage.create_pages(doc):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stopwords = set(stopwords.words('portuguese') + list(punctuation))\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentencas = sent_tokenize(output_string.getvalue().replace('\\n', ' '), language='portuguese')\n",
    "palavras = word_tokenize(output_string.getvalue().replace('\\n', ' ').lower(), language='portuguese')\n",
    "\n",
    "palavrasNoStopW = [palavra for palavra in palavras if palavra not in stopwords]\n",
    "\n",
    "t = nltk.pos_tag(['14/07/21'])\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Problema data\n",
    "    * Como não estou conseguindo pegar a data posso: \n",
    "        * Pegar a data de criação nos metadados\n",
    "        * Se ela for anterior a 3 meses (90 dias) ja discartamos se não seguimos\n",
    "        * E bater os dados com os do portal da transparencia\n",
    "        * Caso forem diferentes dos dados dos ultimos 3 meses do portal damos um erro\n",
    "    * Pros:\n",
    "        * Robusto (OBS)\n",
    "        * Eficiente\n",
    "        * Vai funcionar (na maioria dos casos)\n",
    "    * Contras:\n",
    "        * Não ira funcionar com militares\n",
    "        * Não sera muito robusto na questão de pegar o salario liquído (não tem padrao)\n",
    "    * Outra opção\n",
    "        * Fazer um programa que teste todas as opções possiveis para uma data (ex: 'jan21', '1/21', janeiro 2021')\n",
    "        * OBS:\n",
    "            * De qualquer forma não teremos certeza que aquela data se refere a data do salario do mes x/de competencia pois em todos os documentos os campos tem nomes diferentes\n",
    "            * So seria possivel fazer isso apos termos uma boa amostra com todos os nomes possiveis para os campos\n",
    "                * E mesmo assim o cogigo seria extremamente ineficiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import parsedatetime\n",
    "# cal = parsedatetime.Calendar()\n",
    "\n",
    "# cal.parse('dez 2021')\n",
    "# to = {'a':'b'}\n",
    "# 'acac a c'.translate(to)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
